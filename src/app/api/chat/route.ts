import { NextResponse } from "next/server";
import { ChatOpenAI } from "langchain/chat_models/openai";

/**
 * POST /api/chat
 * body: { content: string }
 */
export async function POST(req: Request) {
  // üü¢ ƒê·ªçc JSON ƒë√∫ng 1 l·∫ßn
  const { content } = await req.json().catch(() => ({}));

  if (!content || typeof content !== "string") {
    return NextResponse.json(
      { error: "Invalid payload" },
      { status: 400 }
    );
  }

  // --- g·ªçi GPT-4o ---
  const llm = new ChatOpenAI({
    modelName: "gpt-4o",
    temperature: 0.7,
  });

  const reply = await llm.call([
    {
      role: "system",
      content:
        "B·∫°n l√† tr·ª£ l√Ω h∆∞·ªõng nghi·ªáp huongnghiep.ai. Lu√¥n m·ªü ƒë·∫ßu: 'Xin ch√†o! T√¥i l√† tr·ª£ l√Ω h∆∞·ªõng nghi·ªáp. C·∫ßn t√¥i gi√∫p g√¨ cho b·∫°n h√¥m nay?'",
    },
    { role: "user", content },
  ]);

  return NextResponse.json({ content: reply.content });
}
